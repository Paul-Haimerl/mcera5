---
title: "Downloading ERA5 data for use with `microclima`, `NicheMapR`, and other microclimate packages"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{mcera5_vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      collapse = TRUE,
                      comment = "#>")
```

## Setup

ERA5 climate data can be downloaded from the climate data store (CDS). The 
following describes how to access the data using R:

1) Register [here](https://cds.climate.copernicus.eu/user/register). 

2) Then, navigate [here](https://cds.climate.copernicus.eu/), login, and click on 
your name (in the top right hand corner) to access your profile. Here you will 
find your user ID (UID) and API key, both which are required for you to remotely 
download data from the CDS. Make a note of these.  

3) You will also need to accept the Ts&Cs (whilst logged in) [here](https://cds.climate.copernicus.eu/cdsapp/#!/terms/licence-to-use-copernicus-products).

The following packages are required:
```{r packages, warning = FALSE, message = FALSE}
library(mcera5)
library(dplyr)
library(ecmwfr)
library(ncdf4)
library(curl)
library(keyring)
library(abind)
library(lubridate)
library(tidync)
library(microclima) # remotes::install_github("ilyamaclean/microclima")
library(NicheMapR) # remotes::install_github("mrke/NicheMapR")
library(microctools) # remotes::install_github("ilyamaclean/microctools")
```

```{r funs, include = FALSE}
#############
##FUNCTIONS##
#############

files_source <- list.files(here::here("R/"), full.names = T)
sapply(files_source,source)
```

#### Set user credentials for API access

```{r creds, eval = FALSE}
# assign your credentials
uid <- "*****"
cds_api_key <- "********-****-****-****-************"

ecmwfr::wf_set_key(user = uid,
                   key = cds_api_key,
                   service = "cds")
```

## Usage

#### Building a request

The first step is to decide on the spatial and temporal extents of the data retrieved from the CDS. There is can be a moderately-sized overhead when submitting a request (and consequently waiting in a queue); at times, when the CDS server is busy, this can entail several hours of waiting for a download to execute, even for small amounts of data (<10 MB). Such overhead time is independent of mcera5, yet can be reduced base upon the spatial/temporal dimensions of the query. It is therefore sensible to be strategic with the number and size of requests submitted. Generally, querying temporal durations greater than one year causes a delay, while query of wide spatial extents can occur rapidly. It is therefore most efficient to download time series data in temporal chunks (e.g. monthly basis) each specifying a region encompassing multiple points of interest. We recommend users [track current usage of the CDS](https://cds.climate.copernicus.eu/live/queue) and follow [ECMWF news](https://confluence.ecmwf.int/#all-updates) (such as the [migration of the MARS Data Centre](https://confluence.ecmwf.int/display/BONDUSER/Data+Centre+Migration+to+Bologna+-+User+Space+Home) between November 2021 and April 2022).

Requests are submitted as whole months, and they will also be split by year, so that they are not too big to handle and to expedite wait times. The splitting of requests which overlap year boundaries is dealt with automatically. Users can request files to be merged together in the `request_era5()` function (covered later on). 

Once these parameters are decided, one can begin to build the request(s) as follows:

```{r build request}

# bounding coordinates (in WGS84 / EPSG:4326)
xmn <- -4
xmx <- -2
ymn <- 49
ymx <- 51

# temporal extent
st_time <- lubridate::ymd("2010:02:26")
en_time <- lubridate::ymd("2010:03:01")


# Set a unique prefix for the filename (here based on spatial
# coordinates), and the file path for downloaded .nc files
file_prefix <- "era5_-4_-2_49_51"
file_path <- getwd()


# build a request (covering multiple years)
req <- build_era5_request(xmin = xmn, xmax = xmx, 
                          ymin = ymn, ymax = ymx,
                          start_time = st_time,
                          end_time = en_time,
                          outfile_name = file_prefix)
```

Requests are stored in list format. Each request (divided by year) are stored as list
objects within the master list:

```{r list_view}
str(req)
```

#### Obtaining data with a request

The next step is to execute the requests, by sending them to the CDS. Executing `request_era5` will download .nc files for each year to the location defined by `out_path`. The filenames will have a prefix defined by `outfile_name` in `build_era5_request`. The `request_era5` function will deal with lists containing multiple requests (i.e. those created by `build_era5_request` with temporal extents spanning multiple years). If users specify a duration longer than one year, the query is downloaded as a separate netCDF file for each year; users can combine files into one by specifying the parameter `combine = TRUE` in `request_era5`. At this stage, the user then waits for the netCDF to be downloaded to their machine, and will receive a confirmation message ("ERA5 netCDF file successfully downloaded") from the R console upon completion:

```{r send_request, eval = FALSE}
request_era5(request = req, uid = uid, out_path = file_path)
```

#### Processing .nc files


Once all .nc files are downloaded, the next step is to extract climate variables conforming to desired spatial and temporal extents from them. This can be done for a single point in space with `extract_clim`. The function outputs a dataframe where each row is a single observation in time and space and each column is a climatic variable. Note that this function uses the same start and end times defined prior to building the request.  

By default, `extract_clim` applies an inverse distance weighting calculation (controlled by the parameter `d_weight`). This means that if the user requests data for a point that does not match the regular grid found in the ERA5 dataset (i.e., the centre point of each ERA5 grid cell), the four nearest neighbouring data points to the requested location will be used to create a weighted average of each climate variable, thereby providing a more likely estimate of location conditions. 

Furthermore, `extract_clim` by default applies a diurnal temperature range correction to the data (when `dtr_cor = TRUE` and weighted according to `dtr_cor_fac`). The diurnal temperature ranges of ERA5 are artificially lower in grid cells classed as sea as opposed to land. It may thus be useful to apply a correction if estimates are required for a terrestrial location in predominantly marine grid cells. If applied, an internal function is evoked that uses the land/sea value in the downloaded NetCDF file to adjust temperature values by the factor provided using the formula $DTR_C=DTR[(1-p_l ) C_f+1]$ where $DTR_C$ is the corrected diurnal temperature range, $DTR$ is the diurnal temperature range in the ERA5 dataset, $p_l$ is the proportion of the grid cell that is land and $C_f$ is the correction factor. The default function input value is a correction based on calibration against the UK Met Office 1-km2 gridded dataset of daily maximum and minimum temperatures, itself calibrated and validated against a network of (on average) 1,203 weather stations distributed across the UK. 

Given that `runauto` in the `microclima` package, as well as functions from the `NicheMapR` and `microclimc` microclimate modelling packages, all only accept date ranges within single years, you will need to create a separate data frame for each yearly block. For example, if your period of interest spans multiple years (and you have used the previous code to download multiple .nc files, run this next block of code for each year):

```{r process_clim, eval = FALSE}
# list the path of the .nc file for a given year
my_nc <- paste0(getwd(), "/era5_-4_-2_49_51_2010.nc")

# for a single point (make sure it's within the bounds of your .nc file)
x <- -3.654600
y <- 50.640369

# gather all hourly variables
point_out <- extract_clim(nc = my_nc, long = x, lat = y,
                            start_time = st_time,  end_time = en_time)
head(point_out)
```



In the same fashion, use `extract_precip` to acquire precipitation from your downloaded netCDF file, which also applies an inverse distance weighting calculation. By default, `extract_precip` sums up hourly ERA5 precipitation to the daily level, which is required for the aforementioned microclimate models. However users can instead receive hourly values by setting `convert_daily = FALSE`. 

```{r process_precip, eval = FALSE}
# gather daily precipitation (we specify to convert precipitation from hourly
# to daily, which is already the default behavior)
point_out_precip <- extract_precip(nc = my_nc, long = x, lat = y,
                                   start_time = st_time,  
                                   end_time = en_time,
                                   convert_daily = TRUE)
```

The dataframe created by `extract_clim` and vector created by `extract_precip` are ready to be used as inputs to the `runauto` function from the `microclima` package:

```{r runauto_example, eval = FALSE}
# create a 200 x 200 30 m spatial resoltuion DEM for location
r <- microclima::get_dem(lat = y, long = x, resolution = 30)

# change date format to fit runauto requirements
temps <- microclima::runauto(r = r, dstart = "26/02/2010",dfinish = "01/03/2010", 
                             hgt = 0.1, l = NA, x = NA, 
                             habitat = "Barren or sparsely vegetated",
                             hourlydata = point_out, 
                             dailyprecip = point_out_precip, 
                             plot.progress= FALSE)
```

For use of climate data with other microclimate packages, such as `microclimc` and `microclimf`, you may need to reformat the climate data using `microctools::hourlyncep_convert`:

```{r hourlyncep_convert_example, eval = FALSE}
climdata <- hourlyncep_convert(climdata = point_out, lat = y, long = x)
```


#### Acknowledgements

Thank you to Koen Hufkens, creator of the `ecwmfr` package for making the aquisition of ECWMF data through R possible. 
